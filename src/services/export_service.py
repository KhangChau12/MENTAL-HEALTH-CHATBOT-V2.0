"""
Export Service - Complete implementation for PDF and JSON export
Generates professional assessment reports with charts and recommendations
"""

import logging
import json
import os
from typing import Dict, List, Optional, Any, Union
from datetime import datetime
from io import BytesIO
import base64

# For PDF generation
try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.lib import colors
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    from reportlab.platypus import PageBreak, Image as RLImage
    from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_RIGHT
    from reportlab.graphics.shapes import Drawing
    from reportlab.graphics.charts.piecharts import Pie
    from reportlab.graphics.charts.barcharts import VerticalBarChart
    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False
    logging.warning("ReportLab not available. PDF export will be disabled.")

logger = logging.getLogger(__name__)

class ExportService:
    """Service for exporting assessment results to various formats"""
    
    def __init__(self):
        self.supported_formats = ['json']
        if REPORTLAB_AVAILABLE:
            self.supported_formats.append('pdf')
        
        # Vietnamese translations for export
        self.translations = {
            'assessment_types': {
                'phq9': 'ƒê√°nh gi√° Tr·∫ßm c·∫£m (PHQ-9)',
                'gad7': 'ƒê√°nh gi√° Lo √¢u (GAD-7)',
                'dass21_stress': 'ƒê√°nh gi√° CƒÉng th·∫≥ng (DASS-21)',
                'suicide_risk': 'ƒê√°nh gi√° Nguy c∆° T·ª± t·ª≠',
                'initial_screening': 'S√†ng l·ªçc Ban ƒë·∫ßu'
            },
            'severity_levels': {
                'minimal': 'T·ªëi thi·ªÉu',
                'mild': 'Nh·∫π',
                'moderate': 'Trung b√¨nh',
                'moderately_severe': 'Trung b√¨nh n·∫∑ng',
                'severe': 'N·∫∑ng',
                'extremely_severe': 'C·ª±c k·ª≥ n·∫∑ng'
            },
            'categories': {
                'mood': 'T√¢m tr·∫°ng',
                'interest': 'S·ªü th√≠ch',
                'anxiety': 'Lo √¢u',
                'sleep': 'Gi·∫•c ng·ªß',
                'energy': 'NƒÉng l∆∞·ª£ng',
                'appetite': 'ƒÇn u·ªëng',
                'self_worth': 'T·ª± ƒë√°nh gi√°',
                'concentration': 'T·∫≠p trung',
                'psychomotor': 'V·∫≠n ƒë·ªông'
            }
        }
    
    def export_assessment_results(
        self, 
        assessment_data: Dict, 
        export_format: str = 'json',
        include_chat_history: bool = False
    ) -> Dict[str, Any]:
        """
        Export assessment results to specified format
        
        Args:
            assessment_data: Complete assessment data
            export_format: 'pdf' or 'json'
            include_chat_history: Whether to include chat conversation
            
        Returns:
            Dictionary with export result
        """
        try:
            if export_format not in self.supported_formats:
                raise ValueError(f"Unsupported format: {export_format}")
            
            # Validate assessment data
            validated_data = self._validate_assessment_data(assessment_data)
            
            if export_format == 'json':
                return self._export_json(validated_data, include_chat_history)
            elif export_format == 'pdf':
                return self._export_pdf(validated_data, include_chat_history)
            
        except Exception as e:
            logger.error(f"Export failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'message': 'Kh√¥ng th·ªÉ xu·∫•t k·∫øt qu·∫£. Vui l√≤ng th·ª≠ l·∫°i.'
            }
    
    def _validate_assessment_data(self, data: Dict) -> Dict:
        """Validate and clean assessment data"""
        required_fields = ['assessment_type', 'total_score', 'completed_at']
        
        for field in required_fields:
            if field not in data:
                raise ValueError(f"Missing required field: {field}")
        
        # Ensure numeric fields are proper numbers
        if 'total_score' in data:
            data['total_score'] = int(data['total_score'])
        
        if 'max_score' in data:
            data['max_score'] = int(data['max_score'])
        
        # Add missing fields with defaults
        data.setdefault('session_id', 'unknown')
        data.setdefault('severity', {'level': 'unknown', 'label': 'Kh√¥ng x√°c ƒë·ªãnh'})
        data.setdefault('recommendations', [])
        data.setdefault('category_scores', {})
        
        return data
    
    def _export_json(self, data: Dict, include_chat: bool) -> Dict[str, Any]:
        """Export to JSON format"""
        try:
            export_data = {
                'export_info': {
                    'format': 'json',
                    'exported_at': datetime.now().isoformat(),
                    'version': '1.0',
                    'include_chat_history': include_chat
                },
                'assessment': self._prepare_assessment_data(data),
                'results': self._prepare_results_data(data),
                'recommendations': data.get('recommendations', [])
            }
            
            if include_chat and 'chat_history' in data:
                export_data['chat_history'] = data['chat_history']
            
            # Convert to JSON string
            json_string = json.dumps(export_data, ensure_ascii=False, indent=2)
            
            # Generate filename
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            assessment_type = data.get('assessment_type', 'assessment')
            filename = f"ket_qua_{assessment_type}_{timestamp}.json"
            
            return {
                'success': True,
                'format': 'json',
                'data': json_string,
                'filename': filename,
                'size': len(json_string.encode('utf-8')),
                'mime_type': 'application/json'
            }
            
        except Exception as e:
            logger.error(f"JSON export failed: {e}")
            raise
    
    def _export_pdf(self, data: Dict, include_chat: bool) -> Dict[str, Any]:
        """Export to PDF format"""
        if not REPORTLAB_AVAILABLE:
            raise RuntimeError("PDF export not available - ReportLab not installed")
        
        try:
            buffer = BytesIO()
            
            # Create PDF document
            doc = SimpleDocTemplate(
                buffer,
                pagesize=A4,
                rightMargin=inch,
                leftMargin=inch,
                topMargin=inch,
                bottomMargin=inch
            )
            
            # Build PDF content
            story = []
            styles = getSampleStyleSheet()
            
            # Custom styles
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontSize=18,
                spaceAfter=30,
                alignment=TA_CENTER,
                textColor=colors.darkblue
            )
            
            heading_style = ParagraphStyle(
                'CustomHeading',
                parent=styles['Heading2'],
                fontSize=14,
                spaceAfter=12,
                spaceBefore=20,
                textColor=colors.darkblue
            )
            
            # Header
            story.append(Paragraph("B√ÅO C√ÅO K·∫æT QU·∫¢ ƒê√ÅNH GI√Å S·ª®C KH·ªéE T√ÇM TH·∫¶N", title_style))
            story.append(Spacer(1, 20))
            
            # Assessment info
            story.extend(self._build_assessment_info_section(data, styles))
            
            # Results section
            story.extend(self._build_results_section(data, styles))
            
            # Category breakdown
            if data.get('category_scores'):
                story.extend(self._build_category_breakdown(data, styles))
            
            # Recommendations
            if data.get('recommendations'):
                story.extend(self._build_recommendations_section(data, styles))
            
            # Chat history (if requested)
            if include_chat and data.get('chat_history'):
                story.extend(self._build_chat_history_section(data, styles))
            
            # Footer
            story.append(PageBreak())
            story.extend(self._build_footer_section(styles))
            
            # Build PDF
            doc.build(story)
            
            # Get PDF data
            pdf_data = buffer.getvalue()
            buffer.close()
            
            # Generate filename
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            assessment_type = data.get('assessment_type', 'assessment')
            filename = f"bao_cao_{assessment_type}_{timestamp}.pdf"
            
            return {
                'success': True,
                'format': 'pdf',
                'data': base64.b64encode(pdf_data).decode('utf-8'),
                'filename': filename,
                'size': len(pdf_data),
                'mime_type': 'application/pdf'
            }
            
        except Exception as e:
            logger.error(f"PDF export failed: {e}")
            raise
    
    def _prepare_assessment_data(self, data: Dict) -> Dict:
        """Prepare assessment metadata for export"""
        assessment_type = data.get('assessment_type', 'unknown')
        assessment_title = self.translations['assessment_types'].get(
            assessment_type, assessment_type
        )
        
        return {
            'type': assessment_type,
            'title': assessment_title,
            'completed_at': data.get('completed_at'),
            'session_id': data.get('session_id'),
            'total_questions': len(data.get('answers', {})),
            'completion_time': self._calculate_completion_time(data)
        }
    
    def _prepare_results_data(self, data: Dict) -> Dict:
        """Prepare results data for export"""
        severity = data.get('severity', {})
        severity_label = self.translations['severity_levels'].get(
            severity.get('level', 'unknown'), 
            severity.get('label', 'Kh√¥ng x√°c ƒë·ªãnh')
        )
        
        return {
            'total_score': data.get('total_score', 0),
            'max_score': data.get('max_score', 0),
            'percentage': data.get('percentage', 0),
            'severity': {
                'level': severity.get('level', 'unknown'),
                'label': severity_label,
                'color': severity.get('color', '#6b7280')
            },
            'interpretation': self._generate_score_interpretation(data)
        }
    
    def _build_assessment_info_section(self, data: Dict, styles) -> List:
        """Build assessment information section for PDF"""
        elements = []
        
        # Assessment info table
        assessment_info = [
            ['Lo·∫°i ƒë√°nh gi√°:', self.translations['assessment_types'].get(
                data.get('assessment_type'), data.get('assessment_type', 'Kh√¥ng x√°c ƒë·ªãnh')
            )],
            ['Ng√†y th·ª±c hi·ªán:', self._format_datetime(data.get('completed_at'))],
            ['M√£ phi√™n:', data.get('session_id', 'Kh√¥ng c√≥')],
            ['S·ªë c√¢u h·ªèi:', str(len(data.get('answers', {})))],
        ]
        
        table = Table(assessment_info, colWidths=[2*inch, 4*inch])
        table.setStyle(TableStyle([
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 10),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
        ]))
        
        elements.append(table)
        elements.append(Spacer(1, 20))
        
        return elements
    
    def _build_results_section(self, data: Dict, styles) -> List:
        """Build results section for PDF"""
        elements = []
        
        # Results heading
        elements.append(Paragraph("K·∫æT QU·∫¢ ƒê√ÅNH GI√Å", styles['Heading2']))
        
        # Score summary
        total_score = data.get('total_score', 0)
        max_score = data.get('max_score', 0)
        severity = data.get('severity', {})
        
        score_info = [
            ['ƒêi·ªÉm s·ªë t·ªïng:', f"{total_score}/{max_score}"],
            ['Ph·∫ßn trƒÉm:', f"{data.get('percentage', 0)}%"],
            ['M·ª©c ƒë·ªô nghi√™m tr·ªçng:', severity.get('label', 'Kh√¥ng x√°c ƒë·ªãnh')],
        ]
        
        score_table = Table(score_info, colWidths=[2*inch, 2*inch])
        score_table.setStyle(TableStyle([
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 12),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 10),
            ('GRID', (0, 0), (-1, -1), 1, colors.lightgrey),
        ]))
        
        elements.append(score_table)
        elements.append(Spacer(1, 15))
        
        # Interpretation
        interpretation = self._generate_score_interpretation(data)
        elements.append(Paragraph("Gi·∫£i th√≠ch k·∫øt qu·∫£:", styles['Heading3']))
        elements.append(Paragraph(interpretation, styles['Normal']))
        elements.append(Spacer(1, 15))
        
        return elements
    
    def _build_category_breakdown(self, data: Dict, styles) -> List:
        """Build category breakdown section"""
        elements = []
        category_scores = data.get('category_scores', {})
        
        if not category_scores:
            return elements
        
        elements.append(Paragraph("PH√ÇN T√çCH THEO DANH M·ª§C", styles['Heading2']))
        
        # Category table
        category_data = [['Danh m·ª•c', 'ƒêi·ªÉm s·ªë', 'T·ª∑ l·ªá']]
        
        for category, score_data in category_scores.items():
            if category.startswith('_'):  # Skip metadata
                continue
                
            category_name = self.translations['categories'].get(category, category)
            score = score_data.get('score', 0) if isinstance(score_data, dict) else score_data
            count = score_data.get('count', 1) if isinstance(score_data, dict) else 1
            avg_score = score / count if count > 0 else 0
            percentage = min(avg_score * 25, 100)  # Rough percentage conversion
            
            category_data.append([
                category_name,
                f"{score:.1f}",
                f"{percentage:.0f}%"
            ])
        
        category_table = Table(category_data, colWidths=[2.5*inch, 1*inch, 1*inch])
        category_table.setStyle(TableStyle([
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 10),
            ('GRID', (0, 0), (-1, -1), 1, colors.lightgrey),
            ('BACKGROUND', (0, 0), (-1, 0), colors.lightblue),
        ]))
        
        elements.append(category_table)
        elements.append(Spacer(1, 15))
        
        return elements
    
    def _build_recommendations_section(self, data: Dict, styles) -> List:
        """Build recommendations section"""
        elements = []
        recommendations = data.get('recommendations', [])
        
        if not recommendations:
            return elements
        
        elements.append(Paragraph("KHUY·∫æN NGH·ªä V√Ä H∆Ø·ªöNG D·∫™N", styles['Heading2']))
        
        for i, rec in enumerate(recommendations, 1):
            rec_title = rec.get('title', f'Khuy·∫øn ngh·ªã {i}')
            rec_content = rec.get('content', 'Kh√¥ng c√≥ n·ªôi dung')
            rec_type = rec.get('type', 'general')
            
            # Add type indicator
            type_labels = {
                'urgent': 'üö® KH·∫®N C·∫§P',
                'professional': 'üë®‚Äç‚öïÔ∏è CHUY√äN NGHI·ªÜP',
                'lifestyle': 'üí° THAY ƒê·ªîI L·ªêI S·ªêNG',
                'technique': 'üßò K·ª∏ THU·∫¨T',
                'general': 'üìã T·ªîNG QU√ÅT'
            }
            
            type_label = type_labels.get(rec_type, 'üìã T·ªîNG QU√ÅT')
            
            elements.append(Paragraph(f"{type_label} {rec_title}", styles['Heading3']))
            elements.append(Paragraph(rec_content, styles['Normal']))
            elements.append(Spacer(1, 10))
        
        return elements
    
    def _build_chat_history_section(self, data: Dict, styles) -> List:
        """Build chat history section"""
        elements = []
        chat_history = data.get('chat_history', [])
        
        if not chat_history:
            return elements
        
        elements.append(PageBreak())
        elements.append(Paragraph("L·ªäCH S·ª¨ CU·ªòC TR√í CHUY·ªÜN", styles['Heading2']))
        elements.append(Spacer(1, 10))
        
        for msg in chat_history:
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            timestamp = msg.get('timestamp', '')
            
            # Format role
            role_display = 'üë§ B·∫°n:' if role == 'user' else 'ü§ñ Tr·ª£ l√Ω:'
            
            # Add message
            elements.append(Paragraph(f"<b>{role_display}</b>", styles['Normal']))
            elements.append(Paragraph(content, styles['Normal']))
            
            if timestamp:
                time_str = self._format_datetime(timestamp, include_time=True)
                elements.append(Paragraph(f"<i>{time_str}</i>", styles['Normal']))
            
            elements.append(Spacer(1, 8))
        
        return elements
    
    def _build_footer_section(self, styles) -> List:
        """Build footer section"""
        elements = []
        
        elements.append(Paragraph("TH√îNG TIN QUAN TR·ªåNG", styles['Heading2']))
        
        disclaimer = """
        <b>L∆∞u √Ω quan tr·ªçng:</b><br/>
        ‚Ä¢ K·∫øt qu·∫£ n√†y ch·ªâ mang t√≠nh ch·∫•t s√†ng l·ªçc v√† tham kh·∫£o<br/>
        ‚Ä¢ Kh√¥ng thay th·∫ø cho vi·ªác ch·∫©n ƒëo√°n y t·∫ø chuy√™n nghi·ªáp<br/>
        ‚Ä¢ N·∫øu b·∫°n c√≥ c√°c tri·ªáu ch·ª©ng nghi√™m tr·ªçng, h√£y t√¨m ki·∫øm s·ª± h·ªó tr·ª£ t·ª´ chuy√™n gia<br/>
        ‚Ä¢ Trong tr∆∞·ªùng h·ª£p kh·∫©n c·∫•p, h√£y g·ªçi ƒë∆∞·ªùng d√¢y n√≥ng: 1800-0011<br/><br/>
        
        <b>Li√™n h·ªá h·ªó tr·ª£:</b><br/>
        ‚Ä¢ ƒê∆∞·ªùng d√¢y n√≥ng s·ª©c kh·ªèe t√¢m th·∫ßn: 1900-6048<br/>
        ‚Ä¢ C·∫•p c·ª©u: 113<br/>
        ‚Ä¢ Website: https://mentalhealth.gov.vn<br/><br/>
        
        B√°o c√°o ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông v√†o {export_time}
        """.format(export_time=datetime.now().strftime('%d/%m/%Y l√∫c %H:%M'))
        
        elements.append(Paragraph(disclaimer, styles['Normal']))
        
        return elements
    
    def _generate_score_interpretation(self, data: Dict) -> str:
        """Generate interpretation text for the score"""
        total_score = data.get('total_score', 0)
        max_score = data.get('max_score', 1)
        assessment_type = data.get('assessment_type', '')
        severity = data.get('severity', {}).get('level', 'unknown')
        
        percentage = (total_score / max_score) * 100 if max_score > 0 else 0
        
        # Type-specific interpretations
        if assessment_type == 'phq9':
            if severity == 'minimal':
                return f"ƒêi·ªÉm s·ªë {total_score}/27 ({percentage:.0f}%) cho th·∫•y c√°c tri·ªáu ch·ª©ng tr·∫ßm c·∫£m ·ªü m·ª©c t·ªëi thi·ªÉu. T√¨nh tr·∫°ng s·ª©c kh·ªèe t√¢m th·∫ßn hi·ªán t·∫°i kh√° t·ªët."
            elif severity == 'mild':
                return f"ƒêi·ªÉm s·ªë {total_score}/27 ({percentage:.0f}%) cho th·∫•y c√°c tri·ªáu ch·ª©ng tr·∫ßm c·∫£m nh·∫π. N√™n ch√∫ √Ω theo d√µi v√† √°p d·ª•ng c√°c bi·ªán ph√°p chƒÉm s√≥c b·∫£n th√¢n."
            elif severity == 'moderate':
                return f"ƒêi·ªÉm s·ªë {total_score}/27 ({percentage:.0f}%) cho th·∫•y c√°c tri·ªáu ch·ª©ng tr·∫ßm c·∫£m ·ªü m·ª©c trung b√¨nh. Khuy·∫øn ngh·ªã tham kh·∫£o √Ω ki·∫øn chuy√™n gia."
            else:
                return f"ƒêi·ªÉm s·ªë {total_score}/27 ({percentage:.0f}%) cho th·∫•y c√°c tri·ªáu ch·ª©ng tr·∫ßm c·∫£m nghi√™m tr·ªçng. C·∫ßn t√¨m ki·∫øm s·ª± h·ªó tr·ª£ chuy√™n nghi·ªáp ngay l·∫≠p t·ª©c."
        
        elif assessment_type == 'gad7':
            if severity == 'minimal':
                return f"ƒêi·ªÉm s·ªë {total_score}/21 ({percentage:.0f}%) cho th·∫•y m·ª©c ƒë·ªô lo √¢u t·ªëi thi·ªÉu. T√¨nh tr·∫°ng lo √¢u hi·ªán t·∫°i trong gi·ªõi h·∫°n b√¨nh th∆∞·ªùng."
            elif severity == 'mild':
                return f"ƒêi·ªÉm s·ªë {total_score}/21 ({percentage:.0f}%) cho th·∫•y m·ª©c ƒë·ªô lo √¢u nh·∫π. C√≥ th·ªÉ √°p d·ª•ng c√°c k·ªπ thu·∫≠t th∆∞ gi√£n v√† qu·∫£n l√Ω cƒÉng th·∫≥ng."
            else:
                return f"ƒêi·ªÉm s·ªë {total_score}/21 ({percentage:.0f}%) cho th·∫•y m·ª©c ƒë·ªô lo √¢u ƒë√°ng quan ng·∫°i. N√™n t√¨m ki·∫øm s·ª± h·ªó tr·ª£ t·ª´ chuy√™n gia t√¢m l√Ω."
        
        else:
            # Generic interpretation
            if percentage <= 25:
                return f"ƒêi·ªÉm s·ªë {total_score}/{max_score} ({percentage:.0f}%) cho th·∫•y t√¨nh tr·∫°ng t·ªët v·ªõi √≠t d·∫•u hi·ªáu ƒë√°ng lo ng·∫°i."
            elif percentage <= 50:
                return f"ƒêi·ªÉm s·ªë {total_score}/{max_score} ({percentage:.0f}%) cho th·∫•y m·ªôt s·ªë d·∫•u hi·ªáu c·∫ßn ch√∫ √Ω v√† theo d√µi."
            elif percentage <= 75:
                return f"ƒêi·ªÉm s·ªë {total_score}/{max_score} ({percentage:.0f}%) cho th·∫•y c√°c d·∫•u hi·ªáu ƒë√°ng quan ng·∫°i, n√™n t√¨m ki·∫øm h·ªó tr·ª£."
            else:
                return f"ƒêi·ªÉm s·ªë {total_score}/{max_score} ({percentage:.0f}%) cho th·∫•y t√¨nh tr·∫°ng nghi√™m tr·ªçng, c·∫ßn h·ªó tr·ª£ chuy√™n nghi·ªáp ngay l·∫≠p t·ª©c."
    
    def _calculate_completion_time(self, data: Dict) -> Optional[str]:
        """Calculate assessment completion time"""
        started_at = data.get('started_at')
        completed_at = data.get('completed_at')
        
        if not started_at or not completed_at:
            return None
        
        try:
            start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
            end_time = datetime.fromisoformat(completed_at.replace('Z', '+00:00'))
            duration = end_time - start_time
            
            minutes = int(duration.total_seconds() / 60)
            seconds = int(duration.total_seconds() % 60)
            
            if minutes > 0:
                return f"{minutes} ph√∫t {seconds} gi√¢y"
            else:
                return f"{seconds} gi√¢y"
        except:
            return None
    
    def _format_datetime(self, dt_string: Optional[str], include_time: bool = False) -> str:
        """Format datetime string for display"""
        if not dt_string:
            return 'Kh√¥ng c√≥ th√¥ng tin'
        
        try:
            dt = datetime.fromisoformat(dt_string.replace('Z', '+00:00'))
            dt = dt.replace(tzinfo=None)  # Remove timezone for local display
            
            if include_time:
                return dt.strftime('%d/%m/%Y l√∫c %H:%M')
            else:
                return dt.strftime('%d/%m/%Y')
        except:
            return str(dt_string)
    
    def get_export_preview(self, assessment_data: Dict, export_format: str) -> Dict:
        """
        Generate a preview of export data
        
        Args:
            assessment_data: Assessment data
            export_format: Format to preview ('pdf' or 'json')
            
        Returns:
            Preview data or None if failed
        """
        try:
            assessment = assessment_data
            
            preview = {
                'export_format': export_format,
                'assessment_type': assessment.get('assessment_type'),
                'assessment_title': self.translations['assessment_types'].get(
                    assessment.get('assessment_type'), 
                    assessment.get('assessment_type', 'Kh√¥ng x√°c ƒë·ªãnh')
                ),
                'completion_status': 'completed' if assessment.get('completed_at') else 'in_progress',
                'total_score': assessment.get('total_score'),
                'max_score': assessment.get('max_score'),
                'severity': assessment.get('severity'),
                'question_count': len(assessment.get('answers', {})),
                'has_recommendations': bool(assessment.get('recommendations')),
                'has_chat_history': bool(assessment.get('chat_history')),
                'estimated_file_size': self._estimate_file_size(assessment, export_format)
            }
            
            return preview
            
        except Exception as e:
            logger.error(f"Error generating preview: {e}")
            return None
    
    def _estimate_file_size(self, assessment_data: Dict, export_format: str) -> str:
        """Estimate file size for export"""
        try:
            # Base size estimation
            base_size = 5000  # 5KB base
            
            # Add size for answers
            answers_size = len(assessment_data.get('answers', {})) * 100
            
            # Add size for recommendations
            rec_size = len(assessment_data.get('recommendations', [])) * 200
            
            # Add size for chat history
            chat_size = 0
            if assessment_data.get('chat_history'):
                chat_messages = assessment_data['chat_history']
                chat_size = sum(len(msg.get('content', '')) for msg in chat_messages) * 2
            
            total_size = base_size + answers_size + rec_size + chat_size
            
            # PDF is typically larger
            if export_format == 'pdf':
                total_size *= 3
            
            # Format size
            if total_size < 1024:
                return f"{total_size} bytes"
            elif total_size < 1024 * 1024:
                return f"{total_size / 1024:.1f} KB"
            else:
                return f"{total_size / (1024 * 1024):.1f} MB"
                
        except:
            return "Kh√¥ng x√°c ƒë·ªãnh"
    
    def validate_export_data(self, assessment_data: Dict) -> Dict[str, Any]:
        """
        Validate data before export
        
        Returns:
            Validation result with any issues found
        """
        issues = []
        warnings = []
        
        # Check required fields
        required_fields = ['assessment_type', 'total_score', 'completed_at']
        for field in required_fields:
            if field not in assessment_data:
                issues.append(f"Thi·∫øu tr∆∞·ªùng b·∫Øt bu·ªôc: {field}")
        
        # Check data quality
        if assessment_data.get('total_score') is None:
            warnings.append("ƒêi·ªÉm s·ªë kh√¥ng ƒë∆∞·ª£c x√°c ƒë·ªãnh")
        
        if not assessment_data.get('answers'):
            warnings.append("Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi ƒë∆∞·ª£c l∆∞u")
        
        if not assessment_data.get('recommendations'):
            warnings.append("Kh√¥ng c√≥ khuy·∫øn ngh·ªã")
        
        return {
            'valid': len(issues) == 0,
            'issues': issues,
            'warnings': warnings,
            'can_export': len(issues) == 0
        }

# Factory function for easy usage
def create_export_service() -> ExportService:
    """Create and return an ExportService instance"""
    return ExportService()

# Utility function for quick export
def export_assessment(
    assessment_data: Dict, 
    format: str = 'json',
    include_chat: bool = False
) -> Dict[str, Any]:
    """
    Quick utility function for exporting assessment results
    
    Args:
        assessment_data: Assessment data to export
        format: Export format ('json' or 'pdf')
        include_chat: Whether to include chat history
        
    Returns:
        Export result dictionary
    """
    service = create_export_service()
    return service.export_assessment_results(assessment_data, format, include_chat)